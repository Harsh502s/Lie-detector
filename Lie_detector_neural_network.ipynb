{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anushree-B/Lie-detector/blob/main/Lie_detector_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SkwJHyqGRN_D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gN8rfgd3Ra5w",
        "outputId": "56e3288a-efb5-4560-f224-34e97ec06025"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.17.0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z46W-YvsRg-H"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Data/politifact_cleaned.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "1I7AQ3qLRvvh",
        "outputId": "8cee4744-e63a-4376-e081-33a9183db2de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Politician</th>\n",
              "      <th>Quote</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_length</th>\n",
              "      <th>adv_count</th>\n",
              "      <th>adj_count</th>\n",
              "      <th>noun_count</th>\n",
              "      <th>verb_count</th>\n",
              "      <th>det_count</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>named_entities</th>\n",
              "      <th>named_entities_count</th>\n",
              "      <th>Truth value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>says that under his presidency  the unemployme...</td>\n",
              "      <td>20</td>\n",
              "      <td>5.050000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-0.4404</td>\n",
              "      <td>('american', 'NORP')</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>in the u s    a person can be married in the m...</td>\n",
              "      <td>24</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>('afternoon', 'TIME')</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>texas republicans just voted to give a republi...</td>\n",
              "      <td>24</td>\n",
              "      <td>5.416667</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>('texas', 'GPE'), ('republicans', 'NORP'), ('r...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>the uk has had zero school shootings since  it...</td>\n",
              "      <td>17</td>\n",
              "      <td>4.352941</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-0.3400</td>\n",
              "      <td>('uk', 'GPE'), ('zero', 'CARDINAL')</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>we cut black child poverty in half in      bec...</td>\n",
              "      <td>14</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.4215</td>\n",
              "      <td>('half', 'CARDINAL')</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Politician                                              Quote  word_count  \\\n",
              "0           5  says that under his presidency  the unemployme...          20   \n",
              "1           5  in the u s    a person can be married in the m...          24   \n",
              "2           2  texas republicans just voted to give a republi...          24   \n",
              "3           4  the uk has had zero school shootings since  it...          17   \n",
              "4           5  we cut black child poverty in half in      bec...          14   \n",
              "\n",
              "   word_length  adv_count  adj_count  noun_count  verb_count  det_count  \\\n",
              "0     5.050000       13.0       13.0        13.0        13.0       13.0   \n",
              "1     3.666667       16.0       16.0        16.0        16.0       16.0   \n",
              "2     5.416667       21.0       21.0        21.0        21.0       21.0   \n",
              "3     4.352941       12.0       12.0        12.0        12.0       12.0   \n",
              "4     4.000000        9.0        9.0         9.0         9.0        9.0   \n",
              "\n",
              "   sentiment                                     named_entities  \\\n",
              "0    -0.4404                               ('american', 'NORP')   \n",
              "1     0.0000                              ('afternoon', 'TIME')   \n",
              "2    -0.2500  ('texas', 'GPE'), ('republicans', 'NORP'), ('r...   \n",
              "3    -0.3400                ('uk', 'GPE'), ('zero', 'CARDINAL')   \n",
              "4    -0.4215                               ('half', 'CARDINAL')   \n",
              "\n",
              "   named_entities_count  Truth value  \n",
              "0                     1          1.0  \n",
              "1                     1          1.0  \n",
              "2                     3          1.0  \n",
              "3                     2          1.0  \n",
              "4                     1          1.0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NYgtIPuMqeh"
      },
      "source": [
        "# Applying neural network model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Truth value\n",
            "3    2405\n",
            "2     410\n",
            "1     293\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Drop rows with NaN values\n",
        "df['Truth value'] = df['Truth value'].astype(int)\n",
        "print(df['Truth value'].isna().sum())\n",
        "print(df['Truth value'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df['Quote']\n",
        "y = df['Truth value']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42,stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vectorize the text\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Github\\Lie-detector\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Github\\Lie-detector\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[MLPClassifier(), 0.7218649517684887, 0.6947452631968487, 0.7218649517684887, 0.6746938502075022]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Github\\Lie-detector\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "d:\\Github\\Lie-detector\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import the machine learning model and train it\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score, recall_score, precision_score\n",
        "\n",
        "models = [LogisticRegression(max_iter=1000), DecisionTreeClassifier(), \n",
        "        RandomForestClassifier(n_estimators=200), SVC(), MLPClassifier(),\n",
        "        MultinomialNB(), BernoulliNB()]\n",
        "\n",
        "results = []\n",
        "# Logistic Regression\n",
        "for model in models:\t\t\t\t\n",
        "\t\tmodel.fit(X_train_vectorized, y_train)\n",
        "\t\ty_pred = model.predict(X_test_vectorized) #Type: ignore\n",
        "\t\t# print(\"Model: \", model)\n",
        "\t\t# print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\t\t# print(\"F1 Score: \", f1_score(y_test, y_pred, average = 'weighted'))\n",
        "\t\t# print(\"Recall: \", recall_score(y_test, y_pred, average = 'weighted'))\n",
        "\t\t# print(\"Precision: \", precision_score(y_test, y_pred, average = 'weighted'))\n",
        "\t\t# print(classification_report(y_test, y_pred))\n",
        "\t\tresults.append([model, accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average = 'weighted'), recall_score(y_test, y_pred, average = 'weighted'), precision_score(y_test, y_pred, average = 'weighted')])\n",
        "\t\tprint(\"\\n\\n\")\n",
        "\n",
        "# Save the best model\n",
        "best_model = max(results, key = lambda x: x[2])\n",
        "print(best_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS_zfbP-190e"
      },
      "source": [
        "# Predicting result with new quote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFqtV4DGivl1",
        "outputId": "c824c168-6a4e-4017-c2f0-da59f574ad5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger') #used for tagging words with their parts of speech (POS)\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = list(df['Quote'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 42,stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "\n",
        "max_len = 100\n",
        "max_features = 10000\n",
        "embed_size = 300\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train)+list(X_test))\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test= tokenizer.texts_to_sequences(X_test)\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM2DkddZF1hpyIbR5LtiLHb",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
